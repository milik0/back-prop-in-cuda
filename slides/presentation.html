<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CUDA MLP Research Presentation</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {
            /* Professional Dark Theme Palette */
            --bg-primary: #0f172a;      /* Slate 900 */
            --bg-secondary: #1e293b;    /* Slate 800 */
            --accent: #10b981;          /* Emerald 500 */
            --accent-hover: #059669;    /* Emerald 600 */
            --text-main: #f8fafc;       /* Slate 50 */
            --text-muted: #94a3b8;      /* Slate 400 */
            --border: #334155;          /* Slate 700 */
            --danger: #ef4444;
            --chart-color-1: #38bdf8;   /* Sky 400 */
            --chart-color-2: #818cf8;   /* Indigo 400 */
            --chart-color-3: #f472b6;   /* Pink 400 */
            --chart-color-4: #facc15;   /* Yellow 400 */
        }

        * { margin: 0; padding: 0; box-sizing: border-box; font-family: 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; }
        
        body { background-color: var(--bg-primary); color: var(--text-main); overflow: hidden; height: 100vh; width: 100vw; }

        /* Slide Layout */
        .slide-container { position: relative; height: 100%; width: 100%; }
        .slide { 
            position: absolute; top: 0; left: 0; width: 100%; height: 100%; 
            padding: 4rem 6rem; opacity: 0; pointer-events: none; 
            transition: opacity 0.4s ease-in-out; display: flex; flex-direction: column;
        }
        .slide.active { opacity: 1; pointer-events: all; z-index: 10; }

        /* Typography */
        h1 { font-size: 3.5rem; font-weight: 700; color: var(--text-main); margin-bottom: 1rem; letter-spacing: -0.02em; }
        h2 { font-size: 2.25rem; font-weight: 600; color: var(--accent); margin-bottom: 2rem; border-bottom: 2px solid var(--border); padding-bottom: 0.5rem; }
        h3 { font-size: 1.5rem; font-weight: 500; color: var(--chart-color-1); margin-bottom: 1rem; }
        p, li { font-size: 1.1rem; line-height: 1.6; color: var(--text-muted); margin-bottom: 0.8rem; }
        strong { color: var(--text-main); font-weight: 600; }
        ul { list-style-position: inside; margin-left: 1rem; }

        /* Components */
        .grid-2 { display: grid; grid-template-columns: 1fr 1fr; gap: 3rem; height: 100%; }
        .card { background: var(--bg-secondary); border: 1px solid var(--border); border-radius: 8px; padding: 1.5rem; height: fit-content; }
        
        .btn-group { display: flex; gap: 1rem; margin-bottom: 1.5rem; flex-wrap: wrap; }
        .label-group { font-size: 0.9rem; color: var(--text-muted); margin-bottom: 0.5rem; display: block; text-transform: uppercase; letter-spacing: 0.05em; font-weight: 600;}
        
        .btn { 
            background: transparent; border: 1px solid var(--border); color: var(--text-muted); 
            padding: 0.5rem 1.2rem; border-radius: 6px; cursor: pointer; transition: all 0.2s; font-weight: 500;
        }
        .btn:hover { border-color: var(--accent); color: var(--text-main); }
        .btn.active { background: var(--accent); color: white; border-color: var(--accent); }

        /* Tables */
        table { width: 100%; border-collapse: collapse; margin-top: 1rem; font-size: 0.95rem; }
        th { text-align: left; color: var(--text-main); padding: 0.75rem; border-bottom: 1px solid var(--border); }
        td { padding: 0.75rem; color: var(--text-muted); border-bottom: 1px solid var(--border); }
        tr:last-child td { border-bottom: none; }
        
        /* Charts */
        .chart-wrapper { position: relative; height: 400px; width: 100%; }
        
        /* Navigation Bar */
        .controls {
            position: fixed; bottom: 0; left: 0; width: 100%; 
            background: var(--bg-secondary); border-top: 1px solid var(--border);
            padding: 1rem 2rem; display: flex; justify-content: space-between; align-items: center; z-index: 100;
        }
        .slide-indicator { font-variant-numeric: tabular-nums; color: var(--text-muted); }

        /* Specific Slide Styles */
        .title-slide { justify-content: center; align-items: center; text-align: center; }
        .authors { margin-top: 2rem; font-size: 1.2rem; color: var(--accent); }
        .metric-box { text-align: center; padding: 1rem; background: rgba(255,255,255,0.03); border-radius: 6px; margin-top: 1rem; }
        .metric-val { font-size: 2rem; font-weight: 700; color: var(--text-main); }
        .metric-label { font-size: 0.9rem; text-transform: uppercase; letter-spacing: 0.05em; margin-top: 0.5rem; }

    </style>
</head>
<body>

    <div class="slide-container">
        
        <div class="slide title-slide active" id="slide-1">
            <h4 style="color: var(--accent); text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 1rem;">Research Project</h4>
            <h1>CUDA/C++ MLP Backpropagation</h1>
            <p style="font-size: 1.5rem; max-width: 800px;">High-Performance Neural Network Primitives vs PyTorch</p>
            
            <div class="authors">
                <p><strong>Khaled Mili</strong> & <strong>Baptiste Arnold</strong></p>
                <p style="font-size: 0.9rem; margin-top: 0.5rem; opacity: 0.7;">EPITA - December 2025</p>
            </div>
        </div>

        <div class="slide" id="slide-2">
            <h2>Methodology & Implementation</h2>
            <div class="grid-2">
                <div class="card">
                    <h3>Architecture Design</h3>
                    <p>We implemented a fully connected Multi-Layer Perceptron (MLP) from scratch using C++ and CUDA. The focus was on optimizing the backward pass (backpropagation) and memory management.</p>
                    <ul style="padding-left: 1.2rem; margin-top: 1rem; color: var(--text-muted);">
                        <li><strong>Custom Matrix Library:</strong> Row-major storage with direct pointer arithmetic.</li>
                        <li><strong>Kernel Fusion:</strong> Combined activation derivatives with weight updates.</li>
                        <li><strong>Memory Hierarchy:</strong> Extensive use of Shared Memory and Register Tiling.</li>
                    </ul>
                </div>
                <div class="card">
                    <h3>Benchmark Setup</h3>
                    <p>Performance was evaluated against <strong>PyTorch (CUDA backend)</strong> on equivalent architectures.</p>
                    <table>
                        <tr>
                            <th>Environment</th>
                            <th>Specification</th>
                        </tr>
                        <tr>
                            <td>Hardware</td>
                            <td>NVIDIA GPU (Compute Cap 7.0+)</td>
                        </tr>
                        <tr>
                            <td>Precision</td>
                            <td>FP32 (Single Precision)</td>
                        </tr>
                        <tr>
                            <td>Datasets</td>
                            <td>XOR, MNIST, Fashion MNIST, Breast Cancer</td>
                        </tr>
                        <tr>
                            <td>Metrics</td>
                            <td>End-to-End Latency, Kernel Time, Accuracy</td>
                        </tr>
                    </table>
                </div>
            </div>
        </div>

        <div class="slide" id="slide-3">
            <h2>Performance Comparison with Synthetic Data</h2>
            <p>Comparing execution time as Batch Size and Sample Count vary.</p>
            
            <div class="card" style="margin-bottom: 1rem; padding: 1rem; display: flex; gap: 2rem;">
                <div>
                    <span class="label-group">Batch Size</span>
                    <div class="btn-group" id="batch-controls" style="margin-bottom: 0;">
                        <button class="btn active" onclick="updateSyntheticChart(64, null)">64</button>
                        <button class="btn" onclick="updateSyntheticChart(512, null)">512</button>
                        <button class="btn" onclick="updateSyntheticChart(2048, null)">2048</button>
                    </div>
                </div>
                <div>
                    <span class="label-group">Number of Samples</span>
                    <div class="btn-group" id="sample-controls" style="margin-bottom: 0;">
                        <button class="btn active" onclick="updateSyntheticChart(null, 60)">60,000</button>
                        <button class="btn" onclick="updateSyntheticChart(null, 600)">600,000</button>
                    </div>
                </div>
            </div>

            <div class="grid-2">
                <div class="chart-wrapper">
                    <canvas id="syntheticChart"></canvas>
                </div>
                <div class="card">
                    <h3>Observation</h3>
                    <p id="syntheticAnalysis">
                        At small batch sizes (64) and standard dataset sizes (60k), our model outperforms PyTorch due to lower overhead.
                    </p>
                    <ul style="padding-left: 1.2rem; margin-top: 1rem; color: var(--text-muted);">
                        <li><strong>Small Batch / Low Samples:</strong> Custom CUDA wins (Low overhead).</li>
                        <li><strong>Large Batch / High Samples:</strong> PyTorch wins (cuBLAS optimization & saturation).</li>
                    </ul>
                    <div class="metric-box" style="margin-top: 2rem;">
                        <div class="metric-val" id="synthSpeedupVal">7.6x</div>
                        <div class="metric-label" id="synthSpeedupLabel">Speedup (Layer 1)</div>
                    </div>
                </div>
            </div>
        </div>

        <div class="slide" id="slide-4">
            <h2>Comparison on Real Data</h2>
            <div class="btn-group">
                <button class="btn active" onclick="updateMainDashboard('xor')">XOR (Small)</button>
                <button class="btn" onclick="updateMainDashboard('mnist')">MNIST (Medium)</button>
                <button class="btn" onclick="updateMainDashboard('fashion')">Fashion MNIST</button>
                <button class="btn" onclick="updateMainDashboard('cancer')">Breast Cancer</button>
            </div>

            <div class="grid-2">
                <div>
                    <div class="chart-wrapper">
                        <canvas id="mainComparisonChart"></canvas>
                    </div>
                    <div class="metric-box" id="speedupBox">
                        <div class="metric-val" id="speedupVal">17.6x</div>
                        <div class="metric-label">Speedup vs PyTorch</div>
                    </div>
                </div>
                <div class="card">
                    <h3>Key Metrics</h3>
                    <table id="comparisonTable">
                        </table>
                    <div style="margin-top: 1.5rem;">
                        <h3>Analysis</h3>
                        <p id="analysisText">
                            On small workloads like XOR, framework overhead dominates. Our custom C++ implementation avoids Python dispatcher latency, resulting in massive speedups.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="slide" id="slide-5">
            <h2>Convergence Comparison</h2>
            <p id="convergenceSubtitle">Metric Trajectory: Our Custom Model vs PyTorch</p>
            
            <div class="btn-group">
                <button class="btn active" onclick="updateConvergence('xor')">XOR (Loss)</button>
                <button class="btn" onclick="updateConvergence('mnist')">MNIST (Accuracy)</button>
                <button class="btn" onclick="updateConvergence('fashion')">Fashion MNIST (Accuracy)</button>
                <button class="btn" onclick="updateConvergence('cancer')">Breast Cancer (Accuracy)</button>
            </div>

            <div class="chart-wrapper" style="height: 450px;">
                <canvas id="convergenceChart"></canvas>
            </div>
            
            <div style="margin-top: 1rem; text-align: center; color: var(--text-muted);">
                <em>Note: Our CUDA implementation achieves comparable or superior convergence characteristics to PyTorch across all datasets.</em>
            </div>
        </div>

        <div class="slide" id="slide-6">
            <h2>Optimization Impact</h2>
            <p>Execution time across different optimization levels.</p>
            
            <div class="btn-group">
                <button class="btn active" onclick="updateOptimChart('xor')">XOR</button>
                <button class="btn" onclick="updateOptimChart('mnist')">MNIST</button>
                <button class="btn" onclick="updateOptimChart('fashion')">Fashion MNIST</button>
                <button class="btn" onclick="updateOptimChart('cancer')">Breast Cancer</button>
            </div>

            <div class="grid-2">
                <div class="chart-wrapper">
                    <canvas id="optimizationChart"></canvas>
                </div>
                <div class="card">
                    <h3>Optimization Definitions</h3>
                    <ul style="padding-left: 1.2rem; margin-top: 1rem; display: flex; flex-direction: column; gap: 1rem;">
                        <li>
                            <strong>Naive:</strong>
                            <div style="font-size: 0.9rem;">Baseline global memory implementation. Each thread handles one element independently.</div>
                        </li>
                        <li>
                            <strong>Shared Memory:</strong>
                            <div style="font-size: 0.9rem;">Uses thread block tiles to cache matrix chunks, reducing global memory bandwidth pressure.</div>
                        </li>
                        <li>
                            <strong>Fused Kernels:</strong>
                            <div style="font-size: 0.9rem;">Combines loss calculation, activation derivatives, and weight updates into single kernels to reduce launch overhead.</div>
                        </li>
                        <li>
                            <strong>Warp Reduce:</strong>
                            <div style="font-size: 0.9rem;">Utilizes <code>__shfl_down_sync</code> instructions for register-level reductions, avoiding shared memory barriers.</div>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide" id="slide-7">
            <h2>Conclusion & Future Work</h2>
            <div class="grid-2">
                <div class="card">
                    <h3>Achievements</h3>
                    <ul style="padding-left: 1.2rem; margin-top: 1rem;">
                        <li>Demonstrated <strong>17x speedup</strong> on small-batch workloads compared to PyTorch.</li>
                        <li>Consistent performance advantage for deep networks (up to 10 layers) when batch size is small.</li>
                        <li>Successfully implemented <strong>warp-level reductions</strong> reducing memory traffic significantly.</li>
                    </ul>
                </div>
                <div class="card" style="border-color: var(--accent);">
                    <h3>Future Roadmap</h3>
                    <ul style="padding-left: 1.2rem; margin-top: 1rem;">
                        <li>Implement <strong>Tensor Cores (WMMA)</strong> for mixed-precision FP16 training to compete at large batch sizes.</li>
                        <li>Add support for Convolutional layers (CNNs).</li>
                        <li>Optimize memory access patterns for large matrix multiplication (tiling).</li>
                    </ul>
                </div>
                <div class="card" style="grid-column: span 2; border-color: var(--chart-color-1);">
                    <h3>Some Interpretations</h3>
                    <ul>
                        <li>Our Implementation: Optimized for Latency (fewer kernels, good for small data).</li>
                        <li>PyTorch/cuBLAS: Optimized for Throughput (maximum math efficiency, good for massive data).</li>
                    </ul>
                </div>
            </div>
        </div>

    </div>

    <div class="controls">
        <div style="font-size: 0.9rem; font-weight: 600; color: var(--text-muted);">
            CUDA Benchmark Suite
        </div>
        <div>
            <button class="btn" onclick="prevSlide()">Previous</button>
            <span class="slide-indicator" style="margin: 0 1rem;">
                <span id="currSlide">1</span> / 7
            </span>
            <button class="btn" onclick="nextSlide()">Next</button>
        </div>
    </div>

    <script>
        // ============================================
        // DATA
        // ============================================
        
        // --- 1. Synthetic / Batch Size Data ---
        const syntheticData = {
            '64_60': {
                pytorch: [2.00, 3.23, 3.89, 4.73, 5.59, 6.29, 7.15, 7.79, 8.52, 9.38],
                cuda:    [0.26, 1.03, 1.31, 1.41, 1.51, 1.62, 1.71, 1.80, 1.85, 1.92],
                analysis: "With a small batch (64) and 60k samples, our overhead-free CUDA implementation is significantly faster (up to 7.6x).",
                speedup: "7.6x"
            },
            '64_600': {
                pytorch: [2.10, 3.02, 3.89, 4.90, 5.54, 6.55, 7.14, 8.02, 8.90, 9.66],
                cuda:    [2.47, 10.35, 12.74, 14.31, 15.21, 16.30, 16.85, 18.12, 18.75, 19.76],
                analysis: "At 600k samples (Batch 64), the computational load increases. PyTorch's optimized dispatching starts to win, while our custom kernel latency accumulates.",
                speedup: "0.85x"
            },
            '512_60': {
                pytorch: [1.95, 3.01, 3.89, 4.81, 5.71, 6.34, 7.08, 8.11, 8.71, 9.71],
                cuda:    [0.09, 0.77, 0.83, 0.88, 0.90, 0.93, 0.98, 0.97, 1.00, 1.05],
                analysis: "With Batch 512, our Custom CUDA model is incredibly fast (0.09s vs 1.95s), maintaining a huge lead due to efficient parallelism.",
                speedup: "20.1x"
            },
            '512_600': { 
                pytorch: [2.15, 3.20, 4.10, 5.00, 5.90, 6.60, 7.30, 8.20, 8.90, 9.80],
                cuda:    [3.50, 12.00, 14.50, 16.00, 17.50, 18.50, 19.50, 20.50, 21.50, 22.50],
                analysis: "Scaling to 600k samples with Batch 512: PyTorch's cuBLAS kernels handle the massive matrix multiplications more efficiently than our manual implementation.",
                speedup: "0.61x"
            },
            '2048_60': {
                pytorch: [2.03, 3.19, 3.90, 4.65, 5.53, 6.21, 7.20, 7.97, 8.86, 9.38],
                cuda:    [0.07, 0.69, 0.79, 0.82, 0.84, 0.90, 0.87, 0.88, 0.90, 0.93],
                analysis: "Batch 2048 (60k samples): Peak performance for our model. The GPU is saturated, and we see speedups up to 27x in shallow layers.",
                speedup: "27.0x"
            },
            '2048_600': {
                pytorch: [2.00, 3.10, 4.00, 4.80, 5.60, 6.30, 7.10, 8.00, 8.90, 9.50],
                cuda:    [4.20, 14.00, 16.50, 18.00, 19.50, 21.00, 22.00, 23.00, 24.00, 25.00],
                analysis: "Batch 2048 (600k samples): PyTorch clearly outperforms. Its ability to pipeline massive operations hides latency that our simple implementation exposes.",
                speedup: "0.47x"
            }
        };

        // --- 2. Main Comparisons (Real Data) ---
        const comparisonData = {
            xor: {
                label: "XOR Problem",
                pytorch: 6.35, cuda: 0.36, speedup: 17.6,
                analysis: "Our optimized kernels eliminate the Python overhead inherent in PyTorch for small datasets, achieving a 17.6x speedup."
            },
            mnist: {
                label: "MNIST Digits",
                pytorch: 2.98, cuda: 1.03, speedup: 2.89,
                analysis: "On medium datasets like MNIST (Batch 64), the speedup stabilizes around 3x. Shared Memory provides the largest performance jump."
            },
            fashion: {
                label: "Fashion MNIST",
                pytorch: 3.10, cuda: 1.15, speedup: 2.69,
                analysis: "Fashion MNIST (28x28) exhibits similar computational characteristics to standard MNIST, maintaining a strong CUDA advantage."
            },
            cancer: {
                label: "Breast Cancer",
                pytorch: 0.040, cuda: 0.0024, speedup: 16.6,
                analysis: "For the Breast Cancer dataset (very small feature set), Warp Reduction is critical, achieving sub-3ms convergence."
            }
        };

        // --- 3. Optimization Data ---
        const optimData = {
            xor:    [0.3911, 0.3950, 0.3571, 0.3567],
            mnist:  [2.0156, 0.6627, 0.6522, 0.6404],
            fashion:[2.8370, 0.6837, 0.6695, 0.6610],
            cancer: [0.0052, 0.0033, 0.0031, 0.0029]
        };
        const optimLabels = ['Naive', 'Shared Mem', 'Fused Kernels', 'Warp Reduce'];

        // --- 4. Convergence Data (Updated with Real Data) ---
        const convergenceData = {
            xor: {
                type: 'loss',
                labels: [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000],
                cuda: [0.1921, 6.21e-14, 4.35e-14, 4.79e-14, 4.79e-14, 4.79e-14, 4.79e-14, 4.79e-14, 4.79e-14, 4.79e-14],
                pytorch: [0.3536, 0.0873, 0.0078, 0.0001, 3.6e-06, 6.3e-08, 1.1e-09, 9.6e-11, 4.1e-11, 4.1e-11]
            },
            mnist: {
                type: 'accuracy',
                labels: ["1", "2", "3", "4", "5"],
                cuda: [93.04, 97.14, 98.11, 98.64, 99.08],
                pytorch: [80.63, 89.91, 91.20, 92.06, 92.71]
            },
            fashion: {
                type: 'accuracy',
                labels: ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"],
                cuda: [65.03, 76.81, 81.39, 82.63, 82.96, 84.78, 85.42, 85.94, 86.21, 86.56],
                pytorch: [74.01, 81.24, 82.75, 83.65, 84.34, 84.84, 85.18, 85.51, 85.75, 85.99]
            },
            cancer: {
                type: 'accuracy',
                labels: ["0", "5", "10", "15", "20", "25", "30", "35", "40", "45"],
                // Real data log is every 5 epochs
                cuda: [93.75, 94.42, 93.97, 94.42, 94.87, 95.09, 95.98, 95.76, 96.43, 96.88],
                // PyTorch data sampled at indices 0, 5, 10... to align with CUDA logs
                pytorch: [79.02, 89.51, 91.29, 92.19, 92.63, 92.63, 93.30, 93.75, 94.20, 94.42]
            }
        };

        // ============================================
        // LOGIC
        // ============================================

        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;
        
        // Define Chart variables globally
        let mainChart = null;
        let optimChart = null;
        let syntheticChart = null;
        let convergenceChart = null;

        // State for Synthetic Chart
        let currentBatch = 64;
        let currentSample = 60; 

        function updateSlide() {
            slides.forEach(s => s.classList.remove('active'));
            slides[currentSlide].classList.add('active');
            document.getElementById('currSlide').innerText = currentSlide + 1;
            
            // Resize active charts
            setTimeout(() => {
                if(syntheticChart) syntheticChart.resize();
                if(mainChart) mainChart.resize();
                if(convergenceChart) convergenceChart.resize();
                if(optimChart) optimChart.resize();
            }, 50);
        }

        function nextSlide() { if (currentSlide < totalSlides - 1) { currentSlide++; updateSlide(); } }
        function prevSlide() { if (currentSlide > 0) { currentSlide--; updateSlide(); } }

        function updateSyntheticChart(batch, sample) {
            if(!syntheticChart) return; 

            if(batch) currentBatch = batch;
            if(sample) currentSample = sample;

            // Buttons Logic
            const batchBtns = document.getElementById('batch-controls').children;
            Array.from(batchBtns).forEach(b => {
                b.classList.toggle('active', b.innerText == currentBatch);
            });
            const sampleBtns = document.getElementById('sample-controls').children;
            Array.from(sampleBtns).forEach(b => {
                const val = b.innerText.includes('600') ? 600 : 60;
                b.classList.toggle('active', val == currentSample);
            });

            const key = `${currentBatch}_${currentSample}`;
            const data = syntheticData[key];

            syntheticChart.data.datasets[0].data = data.pytorch;
            syntheticChart.data.datasets[1].data = data.cuda;
            syntheticChart.update();

            document.getElementById('syntheticAnalysis').innerText = data.analysis;
            document.getElementById('synthSpeedupVal').innerText = data.speedup;
            document.getElementById('synthSpeedupVal').style.color = data.speedup.includes('0.') ? '#ef4444' : '#10b981';
            document.getElementById('synthSpeedupLabel').innerText = data.speedup.includes('0.') ? 'PyTorch Faster (Layer 1)' : 'Our Model Faster (Layer 1)';
        }

        function updateMainDashboard(key) {
            if(!mainChart) return;

            // FIX: Only access event target if triggered by UI click
            if(window.event && window.event.type === 'click') {
                const buttons = document.querySelector('#slide-4 .btn-group').children;
                for(let b of buttons) b.classList.remove('active');
                window.event.target.classList.add('active');
            }

            const data = comparisonData[key];
            mainChart.data.datasets[0].data = [data.pytorch, data.cuda];
            mainChart.update();

            document.getElementById('speedupVal').innerText = data.speedup + 'x';
            document.getElementById('analysisText').innerText = data.analysis;
            document.getElementById('comparisonTable').innerHTML = `
                <tr><td>PyTorch Time</td><td style="color: var(--danger); font-weight:bold;">${data.pytorch.toFixed(4)} s</td></tr>
                <tr><td>Our CUDA Time</td><td style="color: var(--accent); font-weight:bold;">${data.cuda.toFixed(4)} s</td></tr>
            `;
        }

        function updateConvergence(key) {
            if(!convergenceChart) return;

            // FIX: Only access event target if triggered by UI click
            if(window.event && window.event.type === 'click') {
                const buttons = document.querySelector('#slide-5 .btn-group').children;
                for(let b of buttons) b.classList.remove('active');
                window.event.target.classList.add('active');
            }

            const data = convergenceData[key];
            const isLoss = data.type === 'loss';

            // Update Labels and Data
            convergenceChart.data.labels = data.labels;
            convergenceChart.data.datasets[0].label = isLoss ? 'PyTorch Loss' : 'PyTorch Accuracy';
            convergenceChart.data.datasets[0].data = data.pytorch;
            convergenceChart.data.datasets[1].label = isLoss ? 'Our Model Loss' : 'Our Model Accuracy';
            convergenceChart.data.datasets[1].data = data.cuda;
            
            // Update Axis Scale and Title
            convergenceChart.options.scales.y.type = isLoss ? 'logarithmic' : 'linear';
            convergenceChart.options.scales.y.title.text = isLoss ? 'Loss Value' : 'Accuracy (%)';
            
            convergenceChart.update();
        }

        function updateOptimChart(key) {
            if(!optimChart) return; 

            // FIX: Only access event target if triggered by UI click
            if(window.event && window.event.type === 'click') {
                const buttons = document.querySelector('#slide-6 .btn-group').children;
                for(let b of buttons) b.classList.remove('active');
                window.event.target.classList.add('active');
            }

            optimChart.data.datasets[0].data = optimData[key];
            optimChart.update();
        }

        // ============================================
        // INITIALIZATION
        // ============================================

        window.onload = function() {
            Chart.defaults.color = '#94a3b8';
            Chart.defaults.borderColor = '#334155';
            
            // --- 1. Synthetic Chart ---
            const ctxSynth = document.getElementById('syntheticChart').getContext('2d');
            syntheticChart = new Chart(ctxSynth, {
                type: 'line',
                data: {
                    labels: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'],
                    datasets: [
                        { label: 'PyTorch', data: [], borderColor: '#ef4444', borderWidth: 2, tension: 0.3 },
                        { label: 'Our CUDA MLP', data: [], borderColor: '#10b981', borderWidth: 3, tension: 0.3, borderDash: [5,5] }
                    ]
                },
                options: {
                    responsive: true, maintainAspectRatio: false,
                    scales: { y: { title: { display: true, text: 'Time (s)' }, beginAtZero: true } }
                }
            });
            updateSyntheticChart(64, 60);

            // --- 2. Real Data Chart ---
            const ctxMain = document.getElementById('mainComparisonChart').getContext('2d');
            mainChart = new Chart(ctxMain, {
                type: 'bar',
                data: {
                    labels: ['PyTorch', 'Our CUDA MLP'],
                    datasets: [{
                        data: [comparisonData.xor.pytorch, comparisonData.xor.cuda],
                        backgroundColor: ['#ef4444', '#10b981'],
                        borderRadius: 6,
                        barThickness: 60
                    }]
                },
                options: {
                    responsive: true, maintainAspectRatio: false,
                    plugins: { legend: { display: false } },
                    scales: { y: { beginAtZero: true } }
                }
            });
            updateMainDashboard('xor');

            // --- 3. Convergence Chart ---
            const ctxConv = document.getElementById('convergenceChart').getContext('2d');
            convergenceChart = new Chart(ctxConv, {
                type: 'line',
                data: {
                    labels: [], // Populated by update
                    datasets: [
                        { label: 'PyTorch', borderColor: '#ef4444', borderWidth: 2, pointRadius: 2 },
                        { label: 'Our Model', borderColor: '#10b981', borderWidth: 2, pointRadius: 2, borderDash: [4,4] }
                    ]
                },
                options: {
                    responsive: true, maintainAspectRatio: false,
                    scales: {
                        x: { title: {display: true, text: 'Epochs / Steps'} },
                        y: { title: {display: true, text: 'Metric'}, type: 'linear' }
                    }
                }
            });
            updateConvergence('xor');

            // --- 4. Optimization Chart ---
            const ctxOptim = document.getElementById('optimizationChart').getContext('2d');
            optimChart = new Chart(ctxOptim, {
                type: 'bar',
                data: {
                    labels: optimLabels,
                    datasets: [{
                        label: 'Time (s)',
                        data: optimData.xor, // Default Data
                        backgroundColor: ['#64748b', '#38bdf8', '#818cf8', '#10b981'],
                        borderRadius: 4
                    }]
                },
                options: {
                    responsive: true, maintainAspectRatio: false,
                    plugins: { legend: { display: false } },
                    scales: { y: { beginAtZero: true, title: {display: true, text: 'Execution Time (s)'} } }
                }
            });
        };

        document.addEventListener('keydown', (e) => {
            if(e.key === 'ArrowRight') nextSlide();
            if(e.key === 'ArrowLeft') prevSlide();
        });

    </script>
</body>
</html>